---

driver:
  name: ec2
  aws_ssh_key_id: <%= ENV['AWS_SSH_KEY_ID'] %>
  security_group_ids: [ "<%= ENV['AWS_SGROUP_ID'] %>" ]
  region: <%= ENV['AWS_REGION'] %>
  availability_zone: <% ENV['AWS_AVAILABILITY_ZONE'] %>
  instance_type: <%= ENV['AWS_INSTANCE_TYPE'] || 't2.micro' %>
  associate_public_ip: true
  require_chef_omnibus: false
  tags:
    'ansible-role': ansible-role-consul-agent
<% if ENV['AWS_SUBNET'] %>
  subnet_id: <%= ENV['AWS_SUBNET'] %>
<% end %>
<% if ENV['AWS_IAM_PROFILE'] %>
  iam_profile_name: <%= ENV['AWS_IAM_PROFILE'] %>
<% end %>


transport:
  ssh_key: <%= ENV['KITCHEN_SSH_KEY'] %>
  connection_timeout: 120
  connection_retries: 10
  max_ssh_sessions: 4


provisioner:
  name: ansible_playbook
  hosts: 'consul_servers'
  sudo_command: sudo -E -H
  role_name: consul-agent
  require_ansible_repo: false
  require_ansible_source: true
  require_ansible_omnibus: true
  require_chef_for_busser: false
  require_ruby_for_busser: false
  ansible_verbose: false
  ansible_verbosity: warn
  idempotency_test: true


verifier:
  name: shell


# KITCHEN_SSH_KEY must be set manually as it is not passed during the verification step
suites:
  - name: consul
    provisioner:
      playbook: tests/vagrant/consul.yml
    verifier:
      command: KITCHEN_SSH_KEY=<%= ENV['KITCHEN_SSH_KEY'] %> PLAYBOOK=tests/cloud/consul.yml bundle exec rspec -c -I serverspec


# Default for centos-7 image is to persist the root volume.
# The below overrides that.
platforms:
  - name: centos-7
    driver:
      block_device_mappings:
        - device_name: /dev/sda1
          ebs:
            volume_type: standard
            volume_size: 8
            delete_on_termination: true
  - name: debian-8
  - name: ubuntu-14.04
  - name: ubuntu-16.04
